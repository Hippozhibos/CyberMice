{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from utils import load_syllable, rle, get_pose, select_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectPos(test_coor_path, syllable_path, select_syllable, syllable_name):\n",
    "    # pass\n",
    "    test_coor = get_pose(test_coor_path, concatenate=False)\n",
    "    test_syllable = load_syllable(syllable_path)\n",
    "    select_pos_list = select_kp(test_coor, test_syllable, select_syllable, syllable_name)\n",
    "    \n",
    "    return select_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path and selected syllables\n",
    "test_coor_path = r\"D:\\ZhouLab\\HJQ\\mice_3d_pose\\test_session_with_ephys_downsam\\test_with_ephys_filter_downsam_5.npy\"\n",
    "syllable_path = r\"D:\\ZhouLab\\HJQ\\model_test_with_ephys_filter_downsam_5\\20000.0\\results.h5\"\n",
    "select_syllable = 3\n",
    "syllable_name = 'diving'\n",
    "\n",
    "dots_pos = SelectPos(test_coor_path, syllable_path, select_syllable, syllable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 22, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dots_pos[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = np.transpose(dots_pos[5], (0,2,1))\n",
    "\n",
    "# Data processing\n",
    "mujoco_timestep = 0.0025 # unit: s\n",
    "fps = 50 # unit: Hz\n",
    "\n",
    "# Define the time vector based on the original frame rate\n",
    "t_original = np.arange(0, b2.shape[0] * (1 / fps), 1 / fps)\n",
    "\n",
    "# Create a new time vector based on the desired timestep for MuJoCo\n",
    "t_new = np.arange(0, b2.shape[0] * mujoco_timestep, mujoco_timestep)\n",
    "\n",
    "# Initialize arrays to store interpolated data\n",
    "b2_interpolated = np.zeros((len(t_new), b2.shape[1], b2.shape[2]))\n",
    "\n",
    "# Interpolate each dimension separately\n",
    "for i in range(b2.shape[1]):\n",
    "    for j in range(b2.shape[2]):\n",
    "        # Perform cubic spline interpolation\n",
    "        cs = CubicSpline(t_original, b2[:, i, j])\n",
    "        b2_interpolated[:, i, j] = cs(t_new)\n",
    "\n",
    "b2 = b2_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries for angles and skeleton components\n",
    "Dofs = ['root_x', 'root_y', 'root_z', \n",
    "        'root_rot_x', 'root_rot_y', 'root_rot_z',\n",
    "        'neck_x', 'neck_y', 'neck_z',\n",
    "        'RScapula_r1', 'RScapula_r2', 'RScapula_r3', 'RScapula_r4',\n",
    "        'RShoulder_flexion','RShoulder_adduction', 'RShoulder_rotation', \n",
    "        'RElbow_flexion',\n",
    "        'RRadius_rotation', 'RWrist_adduction', 'RWrist_flexion', \n",
    "        'RClavicle_r1', 'RClavicle_r2',\n",
    "        'LScapula_r1', 'LScapula_r2', 'LScapula_r3', 'LScapula_r4',\n",
    "        'LShoulder_flexion','LShoulder_adduction', 'LShoulder_rotation', \n",
    "        'LElbow_flexion',\n",
    "        'LRadius_rotation', 'LWrist_adduction', 'LWrist_flexion', \n",
    "        'LClavicle_r1', 'LClavicle_r2',\n",
    "        'waist_x','waist_y','waist_z',\n",
    "        'RHip_rotation','RHip_flexion','RHip_adduction', \n",
    "        'RKnee_flexion', \n",
    "        'RAnkle_adduction', 'RAnkle_flexion', 'RAnkle_rotation',\n",
    "        'LHip_rotation','LHip_flexion','LHip_adduction', \n",
    "        'LKnee_flexion', \n",
    "        'LAnkle_adduction', 'LAnkle_flexion', 'LAnkle_rotation']\n",
    "\n",
    "Theta = {}\n",
    "\n",
    "for angle in Dofs:\n",
    "    Theta[angle] = np.zeros(b2.shape[0])\n",
    "\n",
    "achor_x = np.array([1, 0, 0])\n",
    "achor_y = np.array([0, 1, 0])\n",
    "achor_z = np.array([0, 0, 1])\n",
    "achor_point = np.array([0, 0, 0])\n",
    "\n",
    "SpineF = b2[:,:,3]\n",
    "SpineM = b2[:,:,4]\n",
    "SpineH = b2[:,:,5]\n",
    "SpineM_f = SpineM\n",
    "SpineM_f[:,2] = b2[:,2,3]\n",
    "SpineM_h = SpineM\n",
    "SpineM_h[:,2] = b2[:,2,5]\n",
    "\n",
    "EarL = b2[:,:,0]\n",
    "EarR = b2[:,:,1]\n",
    "Snout = b2[:,:,2]\n",
    "ForepawL = b2[:,:,8]\n",
    "WristL = b2[:,:,9]\n",
    "ElbowL = b2[:,:,10]\n",
    "ShoulderL = b2[:,:,11]\n",
    "ForepawR = b2[:,:,12]\n",
    "WristR = b2[:,:,13]\n",
    "ElbowR = b2[:,:,14]\n",
    "ShoulderR = b2[:,:,15]\n",
    "HindpawL = b2[:,:,16]\n",
    "AnkleL = b2[:,:,17]\n",
    "KneeL = b2[:,:,18]\n",
    "HindpawR = b2[:,:,19]\n",
    "AnkleR = b2[:,:,20]\n",
    "KneeR = b2[:,:,21]\n",
    "\n",
    "body = {\n",
    "    'world': np.zeros_like(Snout),\n",
    "    'head': Snout-SpineF,'LREar': EarR-EarL,\n",
    "    'root': SpineF-SpineM,\n",
    "    'RLShoulder': ShoulderL-ShoulderR,\n",
    "    'RScapula': ShoulderR-SpineM,\n",
    "    'RHumerus': ElbowR-ShoulderR,'RUlna': WristR-ElbowR, 'RRadius': WristR-ElbowR,'RFinger': ForepawR-WristR,\n",
    "    'LScapula': ShoulderL-SpineM,\n",
    "    'LHumerus': ElbowL-ShoulderL,'LUlna': WristL-ElbowL, 'LRadius': WristL-ElbowL,'LFinger': ForepawL-WristL,\n",
    "    'Pelvis': SpineM-SpineH,\n",
    "    'RFemur': KneeR-SpineH,'RLeg': AnkleR-KneeR,'RPedal': HindpawR-AnkleR,\n",
    "    'LFemur': KneeL-SpineH,'LLeg': AnkleL-KneeL,'LPedal': HindpawL-AnkleL,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(A, B, C, D):\n",
    "    # Calculate the normal vector of the plane\n",
    "    BC = C - B\n",
    "    BD = D - B\n",
    "    normal = np.cross(BC, BD)\n",
    "\n",
    "    # Find the equation of the plane\n",
    "    plane_eq = np.dot(normal, B)\n",
    "\n",
    "    # Determine the distance from A to the plane\n",
    "    distance = np.dot(A, normal) - plane_eq\n",
    "\n",
    "    # Project A onto the plane\n",
    "    projected_A = A - distance * normal\n",
    "\n",
    "    return projected_A\n",
    "\n",
    "def angle(u, v):\n",
    "    dot_product = np.dot(u, v)\n",
    "    magnitude_u = np.linalg.norm(u)\n",
    "    magnitude_v = np.linalg.norm(v)\n",
    "    cosine_theta = dot_product / (magnitude_u * magnitude_v)\n",
    "    angle_rad = np.arccos(np.clip(cosine_theta, -1.0, 1.0))  # Ensure the value is within valid range for arccos\n",
    "    # angle_deg = np.degrees(angle_rad)\n",
    "    return angle_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(b2.shape[0]):\n",
    "    Theta[Dofs[0]][i], Theta[Dofs[1]][i], Theta[Dofs[2]][i] = (SpineF[i,:]+SpineM[i,:])/2\n",
    "\n",
    "    # Theta[Dofs[3]][i] = angle(project(body['RLShoulder'][i], achor_point, achor_y, achor_z), achor_y) \n",
    "    Theta[Dofs[4]][i] = angle(project(body['root'][i], achor_point, achor_x, achor_z), achor_x) - 1.57\n",
    "    Theta[Dofs[5]][i] = angle(project(body['root'][i], achor_point, achor_x, achor_y), achor_x)\n",
    "\n",
    "    Theta[Dofs[6]][i] = angle(project(body['LREar'][i], ShoulderL[i,:], ShoulderR[i,:], (SpineF[i,:] + SpineM[i,:])/2), -1*body['RLShoulder'][i])\n",
    "    Theta[Dofs[7]][i] = angle(project(body['head'][i], SpineF[i,:], SpineM[i,:], SpineM_f[i,:]), (SpineF[i,:]-SpineM_f[i,:])) - np.pi/2\n",
    "    Theta[Dofs[8]][i] = angle(project(body['head'][i], ShoulderL[i,:], ShoulderR[i,:], SpineF[i,:]), (SpineF[i,:]-SpineM_f[i,:])) - 1.57\n",
    "    # Theta[Dofs[8]][i] = angle(project(body['head'][i], achor_point, achor_x, achor_y), project(body['root'][i], achor_point, achor_x, achor_y))\n",
    "\n",
    "    Theta[Dofs[13]][i] = angle(project(body['RHumerus'][i], SpineF[i,:], SpineM[i,:], SpineM_f[i,:]), body['root'][i]) - np.pi\n",
    "    Theta[Dofs[14]][i] = angle(project(body['RHumerus'][i], SpineF[i,:], SpineM[i,:], SpineM_f[i,:]), body['RHumerus'][i])\n",
    "    Theta[Dofs[16]][i] = angle(body['RHumerus'][i], body['RUlna'][i])\n",
    "\n",
    "    Theta[Dofs[18]][i] = angle(project(body['RFinger'][i], ShoulderR[i,:], ElbowR[i,:], WristR[i,:]), body['RFinger'][i]) \n",
    "    Theta[Dofs[19]][i] = angle(project(body['RFinger'][i], ShoulderR[i,:], ElbowR[i,:], WristR[i,:]), body['RUlna'][i]) - 1.57\n",
    "\n",
    "    Theta[Dofs[26]][i] = angle(project(body['LHumerus'][i], SpineF[i,:], SpineM[i,:], SpineM_f[i,:]), body['root'][i]) - np.pi\n",
    "    Theta[Dofs[27]][i] = angle(project(body['LHumerus'][i], SpineF[i,:], SpineM[i,:], SpineM_f[i,:]), body['LHumerus'][i])\n",
    "    Theta[Dofs[29]][i] = angle(body['LHumerus'][i], body['LUlna'][i])\n",
    "\n",
    "    Theta[Dofs[31]][i] = angle(project(body['LFinger'][i], ShoulderL[i,:], ElbowL[i,:], WristL[i,:]), body['LFinger'][i]) \n",
    "    Theta[Dofs[32]][i] = angle(project(body['LFinger'][i], ShoulderL[i,:], ElbowL[i,:], WristL[i,:]), body['LUlna'][i]) - 1.57\n",
    "\n",
    "    Theta[Dofs[36]][i] = angle(project(body['Pelvis'][i], SpineF[i,:], SpineM[i,:], SpineM_f[i,:]), body['root'][i]) - np.pi/2\n",
    "    Theta[Dofs[37]][i] = angle(project(body['Pelvis'][i], SpineF[i,:], SpineM[i,:], SpineM_f[i,:]), body['Pelvis'][i])\n",
    "\n",
    "    Theta[Dofs[39]][i] = angle(project(body['RFemur'][i], SpineH[i,:], SpineM[i,:], SpineM_h[i,:]), body['Pelvis'][i])\n",
    "    Theta[Dofs[40]][i] = angle(project(body['RFemur'][i], SpineH[i,:], SpineM[i,:], SpineM_h[i,:]), body['RFemur'][i])\n",
    "    Theta[Dofs[41]][i] = angle(body['RFemur'][i], body['RLeg'][i])\n",
    "\n",
    "    Theta[Dofs[42]][i] = angle(project(body['RPedal'][i], SpineH[i,:], KneeR[i,:], AnkleR[i,:]), body['RPedal'][i]) \n",
    "    Theta[Dofs[43]][i] = angle(project(body['RPedal'][i], SpineH[i,:], KneeR[i,:], AnkleR[i,:]), body['RLeg'][i])\n",
    "\n",
    "    Theta[Dofs[46]][i] = angle(project(body['LFemur'][i], SpineH[i,:], SpineM[i,:], SpineM_h[i,:]), body['Pelvis'][i])\n",
    "    Theta[Dofs[47]][i] = angle(project(body['LFemur'][i], SpineH[i,:], SpineM[i,:], SpineM_h[i,:]), body['LFemur'][i])\n",
    "    Theta[Dofs[48]][i] = angle(body['LFemur'][i], body['LLeg'][i])\n",
    "\n",
    "    Theta[Dofs[49]][i] = angle(project(body['LPedal'][i], SpineH[i,:], KneeR[i,:], AnkleR[i,:]), body['LPedal'][i]) \n",
    "    Theta[Dofs[50]][i] = angle(project(body['LPedal'][i], SpineH[i,:], KneeR[i,:], AnkleR[i,:]), body['LLeg'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta[Dofs[0]][:] -= np.min(Theta[Dofs[0]])\n",
    "Theta[Dofs[1]][:] -= np.min(Theta[Dofs[1]])\n",
    "Theta[Dofs[2]][:] -= np.min(Theta[Dofs[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary values to a list of arrays\n",
    "Theta_list = [v for v in Theta.values()]\n",
    "\n",
    "# Concatenate the arrays along a new axis (axis=0)\n",
    "qpos = np.concatenate([arr[:, np.newaxis] for arr in Theta_list], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = mujoco_timestep\n",
    "\n",
    "# Compute the change in joint angles\n",
    "dqpos = np.diff(qpos, axis=0)\n",
    "\n",
    "# Compute joint velocities\n",
    "qvel = dqpos / dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qpos does not contain NaN values\n",
      "qvel does not contain NaN values\n"
     ]
    }
   ],
   "source": [
    "if np.isnan(qpos).any():\n",
    "    print(\"qpos contains NaN values\")\n",
    "else:\n",
    "    print(\"qpos does not contain NaN values\")\n",
    "\n",
    "# Check for NaN values in qvel\n",
    "if np.isnan(qvel).any():\n",
    "    print(\"qvel contains NaN values\")\n",
    "else:\n",
    "    print(\"qvel does not contain NaN values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to HDF5 file successfully!\n"
     ]
    }
   ],
   "source": [
    "directory_path = os.path.join('mocap_data', syllable_name)\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "hdf5_file = os.path.join(directory_path,'data.h5')\n",
    "\n",
    "with h5py.File(hdf5_file, 'w') as f:\n",
    "    # Create datasets for qpos and qvel\n",
    "    f.create_dataset('qpos', data=qpos[:-1,:])\n",
    "    f.create_dataset('qvel', data=qvel)\n",
    "\n",
    "print(\"Data written to HDF5 file successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in the HDF5 file:\n",
      "qpos (23, 52)\n",
      "qvel (23, 52)\n",
      "Shape of 'qpos': (23, 52)\n",
      "Shape of 'qvel': (23, 52)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(hdf5_file, 'r') as f:\n",
    "    print(\"Datasets in the HDF5 file:\")\n",
    "    for name in f:\n",
    "        print(name, f[name].shape)\n",
    "\n",
    "    # Check the contents of 'qpos' and 'qvel'\n",
    "    qpos_data = f['qpos'][:]\n",
    "    qvel_data = f['qvel'][:]\n",
    "    print(\"Shape of 'qpos':\", qpos_data.shape)\n",
    "    print(\"Shape of 'qvel':\", qvel_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to HDF5 file successfully!\n"
     ]
    }
   ],
   "source": [
    "timestep_seconds = dt\n",
    "trajectory_lengths = np.array([qvel.shape[0]])\n",
    "directory_path = os.path.join('mocap_data', syllable_name)\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "hdf5_file = os.path.join(directory_path, 'data_revised.h5')\n",
    "\n",
    "with h5py.File(hdf5_file, 'w') as f:\n",
    "    # Create id2name group\n",
    "    id2name_grp = f.create_group('id2name')\n",
    "    # Example datasets within id2name (fill with actual data as needed)\n",
    "    id2name_grp.create_dataset('sites', data=np.array([b'site1', b'site2']))\n",
    "    id2name_grp.create_dataset('joints', data=np.array([b'joint1', b'joint2']))\n",
    "    id2name_grp.create_dataset('other', data=np.array([b'other1', b'other2']))\n",
    "\n",
    "    # Create timestep_seconds dataset\n",
    "    f.create_dataset('timestep_seconds', data=timestep_seconds)\n",
    "\n",
    "    # Create trajectories group\n",
    "    trajectories_grp = f.create_group('trajectories')\n",
    "    \n",
    "    # Create a subgroup for each trajectory\n",
    "    for traj_idx in range(len(trajectory_lengths)):\n",
    "        traj_grp = trajectories_grp.create_group(str(traj_idx).zfill(5))  # Example subgroup name\n",
    "        # traj_grp.create_dataset('root_qpos', data=qpos[:-1,:])  # Example dataset, fill with actual root_qpos data\n",
    "        traj_grp.create_dataset('qpos', data=qpos[:-1,:])\n",
    "        # traj_grp.create_dataset('root_qvel', data=qvel)  # Example dataset, fill with actual root_qvel data\n",
    "        traj_grp.create_dataset('qvel', data=qvel)\n",
    "        # traj_grp.create_dataset('root2site', data=np.random.rand(23, 6))  # Example dataset, fill with actual data\n",
    "        # traj_grp.create_dataset('joint_quat', data=np.random.rand(23, 8))  # Example dataset, fill with actual data\n",
    "\n",
    "    # Create trajectory_lengths dataset\n",
    "    f.create_dataset('trajectory_lengths', data=trajectory_lengths)\n",
    "\n",
    "print(\"Data written to HDF5 file successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level groups: ['id2name', 'timestep_seconds', 'trajectories', 'trajectory_lengths']\n",
      "id2name <HDF5 group \"/id2name\" (3 members)>\n",
      "timestep_seconds <HDF5 dataset \"timestep_seconds\": shape (), type \"<f8\">\n",
      "trajectories <HDF5 group \"/trajectories\" (1 members)>\n",
      "trajectory_lengths <HDF5 dataset \"trajectory_lengths\": shape (1,), type \"<i4\">\n"
     ]
    }
   ],
   "source": [
    "filename_2 = r'D:\\CyberMice\\mocap_data\\mocap_data\\diving\\data_revised.h5'\n",
    "\n",
    "with h5py.File(filename_2, 'r') as f:\n",
    "    # Get a list of top-level groups\n",
    "    print(\"Top-level groups:\", list(f.keys()))\n",
    "\n",
    "    # Get a list of all groups and datasets\n",
    "    for name, obj in f.items():\n",
    "        print(name, obj)\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
