{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title Run to install MuJoCo and `dm_control`\n","import distutils.util\n","import os\n","import subprocess\n","if subprocess.run('nvidia-smi').returncode:\n","  raise RuntimeError(\n","      'Cannot communicate with GPU. '\n","      'Make sure you are using a GPU Colab runtime. '\n","      'Go to the Runtime menu and select Choose runtime type.')\n","\n","# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n","# This is usually installed as part of an Nvidia driver package, but the Colab\n","# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n","# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n","NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n","if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n","  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n","    f.write(\"\"\"{\n","    \"file_format_version\" : \"1.0.0\",\n","    \"ICD\" : {\n","        \"library_path\" : \"libEGL_nvidia.so.0\"\n","    }\n","}\n","\"\"\")\n","\n","# print('Installing dm_control...')\n","# !pip install -q dm_control>=1.0.18\n","\n","# Configure dm_control to use the EGL rendering backend (requires GPU)\n","%env MUJOCO_GL=egl\n","\n","print('Checking that the dm_control installation succeeded...')\n","try:\n","  from dm_control import suite\n","  env = suite.load('cartpole', 'swingup')\n","  pixels = env.physics.render()\n","except Exception as e:\n","  raise e from RuntimeError(\n","      'Something went wrong during installation. Check the shell output above '\n","      'for more information.\\n'\n","      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n","      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n","else:\n","  del pixels, suite\n","\n","!echo Installed dm_control $(pip show dm_control | grep -Po \"(?<=Version: ).+\")"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#@title Other imports and helper functions\n","\n","# General\n","import copy\n","import os\n","import itertools\n","from IPython.display import clear_output\n","import numpy as np\n","\n","# Graphics-related\n","import matplotlib\n","import matplotlib.animation as animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","import PIL.Image\n","# Internal loading of video libraries.\n","\n","# Use svg backend for figure rendering\n","%config InlineBackend.figure_format = 'svg'\n","\n","# Font sizes\n","SMALL_SIZE = 8\n","MEDIUM_SIZE = 10\n","BIGGER_SIZE = 12\n","plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n","plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n","plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n","plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n","plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n","plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n","plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n","\n","# Inline video helper function\n","if os.environ.get('COLAB_NOTEBOOK_TEST', False):\n","  # We skip video generation during tests, as it is quite expensive.\n","  display_video = lambda *args, **kwargs: None\n","else:\n","  def display_video(frames, framerate=30):\n","    height, width, _ = frames[0].shape\n","    dpi = 70\n","    orig_backend = matplotlib.get_backend()\n","    matplotlib.use('Agg')  # Switch to headless 'Agg' to inhibit figure rendering.\n","    fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n","    matplotlib.use(orig_backend)  # Switch back to the original backend.\n","    ax.set_axis_off()\n","    ax.set_aspect('equal')\n","    ax.set_position([0, 0, 1, 1])\n","    im = ax.imshow(frames[0])\n","    def update(frame):\n","      im.set_data(frame)\n","      return [im]\n","    interval = 1000/framerate\n","    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n","                                   interval=interval, blit=True, repeat=False)\n","    return HTML(anim.to_html5_video())\n","\n","# Seed numpy's global RNG so that cell outputs are deterministic. We also try to\n","# use RandomState instances that are local to a single cell wherever possible.\n","np.random.seed(42)"]},{"cell_type":"markdown","metadata":{},"source":["Define Environment"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","from dm_control import viewer\n","from dm_control import composer\n","\n","from tasks.tracking import DotsTracking\n","from assets.CyberMice import Mice\n"]},{"cell_type":"markdown","metadata":{},"source":["Main Loop"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["walker = Mice()\n","ref_path = r'D:\\CyberMice\\mocap_data\\mocap_data\\diving\\data.h5'\n","task = DotsTracking(walker, ref_path)\n","env = composer.Environment(task, random_state=np.random.RandomState(42))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'DotsTracking' object has no attribute '_mocap_sites'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Clamp actions to avoid extreme values\u001b[39;00m\n\u001b[0;32m      8\u001b[0m action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(action, action_spec\u001b[38;5;241m.\u001b[39mminimum, action_spec\u001b[38;5;241m.\u001b[39mmaximum)\n\u001b[1;32m---> 10\u001b[0m time_step \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, discount = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, observations = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     12\u001b[0m     time_step\u001b[38;5;241m.\u001b[39mreward, time_step\u001b[38;5;241m.\u001b[39mdiscount, time_step\u001b[38;5;241m.\u001b[39mobservation))\n","File \u001b[1;32md:\\Anaconda\\envs\\rl\\Lib\\site-packages\\dm_control\\composer\\environment.py:440\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observation_updater\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m physics_is_divergent:\n\u001b[1;32m--> 440\u001b[0m   reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_task\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_physics_proxy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m   discount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task\u001b[38;5;241m.\u001b[39mget_discount(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_physics_proxy)\n\u001b[0;32m    442\u001b[0m   terminating \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    443\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task\u001b[38;5;241m.\u001b[39mshould_terminate_episode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_physics_proxy)\n\u001b[0;32m    444\u001b[0m       \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_physics\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_limit\n\u001b[0;32m    445\u001b[0m   )\n","File \u001b[1;32md:\\CyberMice\\tasks\\tracking.py:143\u001b[0m, in \u001b[0;36mDotsTracking.get_reward\u001b[1;34m(self, physics)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns factorized reward terms.\"\"\"\u001b[39;00m\n\u001b[0;32m    141\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(physics\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol_timestep)\n\u001b[0;32m    142\u001b[0m walker_ft \u001b[38;5;241m=\u001b[39m get_walker_features(physics, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mocap_joints,\n\u001b[1;32m--> 143\u001b[0m                                 \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mocap_sites\u001b[49m)\n\u001b[0;32m    144\u001b[0m reference_ft \u001b[38;5;241m=\u001b[39m get_reference_features(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_snippet, step)\n\u001b[0;32m    145\u001b[0m reward_factors \u001b[38;5;241m=\u001b[39m reward_factors_deep_mimic(\n\u001b[0;32m    146\u001b[0m     walker_features\u001b[38;5;241m=\u001b[39mwalker_ft,\n\u001b[0;32m    147\u001b[0m     reference_features\u001b[38;5;241m=\u001b[39mreference_ft,\n\u001b[0;32m    148\u001b[0m     weights\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n","\u001b[1;31mAttributeError\u001b[0m: 'DotsTracking' object has no attribute '_mocap_sites'"]}],"source":["action_spec = env.action_spec()\n","time_step = env.reset()\n","while not time_step.last():\n","  action = np.random.uniform(action_spec.minimum, action_spec.maximum,\n","                             size=action_spec.shape)\n","  \n","  # Clamp actions to avoid extreme values\n","  action = np.clip(action, action_spec.minimum, action_spec.maximum)\n","  \n","  time_step = env.step(action)\n","  print(\"reward = {}, discount = {}, observations = {}.\".format(\n","      time_step.reward, time_step.discount, time_step.observation))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR:absl:dm_control viewer intercepted an environment error.\n","Original message: 'DotsTracking' object has no attribute '_termination_error'\n","dm_control viewer intercepted an environment error.\n","Original message: 'DotsTracking' object has no attribute '_termination_error'\n","Traceback:\n","  File \"d:\\Anaconda\\envs\\rl\\Lib\\site-packages\\dm_control\\viewer\\runtime.py\", line 254, in _step\n","    self._time_step = self._env.step(action)\n","                      ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"d:\\Anaconda\\envs\\rl\\Lib\\site-packages\\dm_control\\composer\\environment.py\", line 440, in step\n","    reward = self._task.get_reward(self._physics_proxy)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"d:\\CyberMice\\tasks\\tracking.py\", line 161, in get_reward\n","    termination_error=self._termination_error,\n","                      ^^^^^^^^^^^^^^^^^^^^^^^\n"]}],"source":["env.reset()\n","viewer.launch(env)"]}],"metadata":{"kernelspec":{"display_name":"mujoco","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":2}
